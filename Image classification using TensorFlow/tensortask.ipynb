{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport cv2                  \nimport numpy as np  \nfrom tqdm import tqdm\nimport os       \nimport random\nfrom random import shuffle \nimport tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.layers import Flatten,Activation\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR = \"../input/flowers-recognition/flowers\"\nCATEGORIES = os.listdir(\"../input/flowers-recognition/flowers\")\nprint(CATEGORIES)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\ncategories = []\nIMG_SIZE = 100 #28 loses all the info\n\nfor catg in tqdm.tqdm(CATEGORIES):\n    path = os.path.join(DIR,catg)\n    for img_path in os.listdir(path):\n        img_path = os.path.join(path, img_path)\n        try:\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n            img = img / 255.0\n            \n            images.append(img)\n            categories.append(catg)       \n        except:\n            continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(images), len(categories))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=random.randint(0,len(categories))\n        ax[i,j].imshow(images[l])\n        ax[i,j].set_title('Flower: '+categories[l])\n        \nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(images)\nle=LabelEncoder()\ny=le.fit_transform(categories)\nprint(X.shape, y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 5\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(1000, activation='relu'),\n  tf.keras.layers.Dense(500, activation='relu'),\n  tf.keras.layers.Dense(250, activation='relu'),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nepochs = 200\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          verbose = 1,\n          epochs=epochs,\n          validation_data=(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con = tf.confusion_matrix(labels=x_train, predictions=y_train)\nsess = tf.Session()\nwith sess.as_default():\n        print(sess.run(con))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}